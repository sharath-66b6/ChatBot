
# Langchain AI Chat Models Demo

This project demonstrates two implementations of AI-powered chatbot applications using **Langchain** with different large language models (LLMs). The chatbot can respond to user queries based on natural language prompts and can leverage the **OpenAI API** or **Ollama Llama 3.2 model** for responses. The project tracks queries using **Langsmith**.

## Features
- Two separate chatbot demos:
  - **OpenAI API Integration**: Uses the `ChatGroq` model for question answering.
  - **Ollama Llama 3.2 Integration**: Uses `Llama 3.2` model for enhanced language understanding.
- Interactive UI built with **Streamlit** where users can input queries and get real-time responses.
- **Langchain** framework for handling prompts and LLM chaining.
- **Langsmith** tracking enabled to monitor the system's performance and trace the interactions.

## Technology Stack
- **Langchain**: Framework for prompt templates and managing LLM models.
- **Streamlit**: Web framework for building the user interface.
- **OpenAI API**: (In first implementation) for natural language understanding and response generation.
- **Ollama Llama 3.2 API**: (In second implementation) for enhanced natural language model responses.
- **Langsmith**: For API key management and monitoring the interactions.
- **Python**: Core programming language.
- **Dotenv**: For managing environment variables like API keys.

## Installation

### Prerequisites
- **Python 3.7+** installed on your system.
- Create an account with **OpenAI** and **Ollama** to get respective API keys.
- Install the necessary Python libraries.

### Setup Instructions

1. Clone this repository:
   ```bash
   git clone https://github.com/your-username/langchain-ai-chat-demo.git
   cd langchain-ai-chat-demo
   ```

2. Install required packages:
   ```bash
   pip install -r requirements.txt
   ```

3. Set up environment variables:
   - Create a `.env` file in the root of your project directory:
     ```
     GROQ_API_KEY=your_openai_api_key
     LANGSMITH_API=your_langsmith_api_key
     ```

4. Run the Streamlit app:
   ```bash
   streamlit run app_openai.py  # For OpenAI-based demo
   streamlit run app_ollama.py  # For Llama 3.2-based demo
   ```

## Usage

1. Once the app is running, open the web interface using the local URL provided by Streamlit.
2. Enter your query in the input box labeled **"Search the topic u want"**.
3. Depending on the selected model (OpenAI or Ollama Llama 3.2), the app will generate a response and display it on the screen.

### Demo 1: OpenAI API

The **OpenAI API**-powered model (based on `ChatGroq`) provides responses to user queries.

```python
#openAI LLM
llm=ChatGroq(model='mixtral-8x7b-32768')
```
![OpenAI API Demo](C:\Users\user\OneDrive\Pictures\Screenshots\Screenshot 2024-10-17 002857.png) Demo of the chatbot using OpenAI API, showcasing user interaction and responses generated by the model.

### Demo 2: Ollama Llama 3.2 API

The **Ollama Llama 3.2**-powered model offers another method of responding to user queries using a different LLM.

```python
#ollama Llama3.2 LLM
llm=Ollama(model='llama3.2')
```
![Ollama Llama 3.2 Model Demo](C:\Users\user\OneDrive\Pictures\Screenshots\Screenshot 2024-10-17 003957.png) Showcasing the Ollama Llama 3.2 model, highlighting the capabilities of the AI in generating relevant answers to user queries.

### Langsmith Tracking
This project incorporates Langsmith tracking to monitor and analyze the interactions for improved performance.

![Langsmith Tracking](C:\Users\user\OneDrive\Pictures\Screenshots\Screenshot 2024-10-17 003103.png) Visual representation of Langsmith tracking, providing insights into the system's interactions and performance metrics.

## Future Enhancements

- Add more LLMs for comparison.
- Improve the user interface with additional styling and features.
- Implement caching for frequent queries.
- Allow users to choose between models dynamically in a single app.

## Contributors
- **Sharath Kumar Reddy** - AI/ML Engineer, Project Lead
